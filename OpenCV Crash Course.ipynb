{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "height = 322 , width = 600 , depth = 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import imutils\n",
    "\n",
    "\n",
    "# load the input image and show its dimensions, keeping in mind that\n",
    "# images are represented as a multi-dimensional NumPy array with\n",
    "# shape no. rows (height) x no. columns (width) x no. channels (depth)\n",
    "\n",
    "image = cv2.imread('jp.png')\n",
    "(h, w, d) = image.shape\n",
    "print('height = {} , width = {} , depth = {}'.format(h , w , d))\n",
    "\n",
    "# display the image to our screen -- we will need to click the window\n",
    "# open by OpenCV and press a key on our keyboard to continue execution\n",
    "cv2.imshow('Image' , image)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blue = 37 , Green = 49 , Red = 41\n"
     ]
    }
   ],
   "source": [
    "# access RGB pixels located at x=50, y=100\n",
    "# OpenCV uses BGR order rather than RGB\n",
    "#(B, G , R) = image[y, x]\n",
    "(B, G, R) = image[100, 50]\n",
    "print('Blue = {} , Green = {} , Red = {}'.format(B, G ,R))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Array Slicing and Cropping\n",
    "\n",
    "#Extract a 100x100 pixel square ROI (Region of Interest) from the\n",
    "# input image starting at x=320,y=60 at ending at x=420,y=160\n",
    "#image[y-start:y-end, x-start:x-end]\n",
    "roi = image[60:160 , 320:420]\n",
    "cv2.imshow('ROI', roi)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Image Resizing\n",
    "\n",
    "#resize the image to 200x200, ignoring aspect ratio\n",
    "resized = cv2.resize(image, (200,200))\n",
    "cv2.imshow('Fixed Resizing', resized)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# resize without ignoring aspect ratio\n",
    "# resize width to 300 px\n",
    "\n",
    "ratio = 300.0 / w\n",
    "dimension = (300 , int(h*ratio))\n",
    "resized = cv2.resize(image, dimension)\n",
    "cv2.imshow('Resized', resized)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using imutils to resized image\n",
    "resized = imutils.resize(image, height=300)\n",
    "cv2.imshow('Resized' , resized)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rotate image\n",
    "# (-) for clockwise, (+) for counter clockwise\n",
    "# get center and warp affine\n",
    "\n",
    "center = (w//2 , h//2)\n",
    "rotationMatrix = cv2.getRotationMatrix2D(center, -45, 1.0)\n",
    "rotated = cv2.warpAffine(image, rotationMatrix , (w, h))\n",
    "cv2.imshow('OpenCV Rotate' , rotated)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#imutils rotation\n",
    "\n",
    "rotated = imutils.rotate_bound(image, 90)\n",
    "cv2.imshow('imutils rotation' , rotated)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gaussian Blurring\n",
    "# apply 11x11 kernel\n",
    "blurred = cv2.GaussianBlur(image, (11, 11), 0)\n",
    "cv2.imshow('Blurred' , blurred)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drawing\n",
    "\n",
    "# draw a 2px rectangle around faces\n",
    "rectangle = image.copy()\n",
    "cv2.rectangle(rectangle, (320, 60), (420, 160), (0, 0, 255), 2)\n",
    "cv2.imshow('Rectangle', rectangle)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# draw a blue 20px (filled in) circle on the image centered at\n",
    "# x=300,y=150\n",
    "circle = image.copy()\n",
    "cv2.circle(circle, (300, 150), 20, (255, 0, 0) , -1)\n",
    "cv2.imshow('Circle' , circle)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# draw a 5px thick red line from x=60,y=20 to x=400,y=200\n",
    "line = image.copy()\n",
    "cv2.line(line, (60, 20) , (400, 200), (0, 0, 255) , 5)\n",
    "cv2.imshow('Line' , line)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# put text to image\n",
    "\n",
    "output = image.copy()\n",
    "cv2.putText(output, 'OpenCV + Jurassic Park!!' , (10, 25), cv2.FONT_HERSHEY_COMPLEX, 0.7, (0, 255, 0), 2)\n",
    "cv2.imshow('Text', output)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new image\n",
    "image = cv2.imread('tetris_blocks.png')\n",
    "cv2.imshow('Image', image)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert color to Gray Scale\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow('Grayscale' , gray)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# apply edge detection\n",
    "edged = cv2.Canny(gray , 30, 150)\n",
    "cv2.imshow('Edge Detect' , edged)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# threshold the image by setting all pixel values less than 225\n",
    "# to 255 (white; foreground) and all pixel values >= 225 to 255\n",
    "# (black; background), thereby segmenting the image\n",
    "\n",
    "thresh = cv2.threshold(gray, 225, 255, cv2.THRESH_BINARY_INV)[1]\n",
    "cv2.imshow('Treshold', thresh)\n",
    "cv2.waitKey(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find contours (i.e., outlines) of the foreground objects in the\n",
    "# thresholded image\n",
    "\n",
    "contours = cv2.findContours(thresh.copy() , cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "contours = contours[0] if imutils.is_cv2() else contours[1]\n",
    "output = image.copy()\n",
    "\n",
    "# loop over contours\n",
    "for c in contours:\n",
    "    # draw each contour on the output image with a 3px thick purple\n",
    "    # outline, then display the output contours one at a time\n",
    "    cv2.drawContours(output, [c], -1, (240, 0, 159), 3)\n",
    "#     cv2.imshow('Contours' , output)\n",
    "#     cv2.waitKey(0)\n",
    "cv2.imshow('Contours' , output)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# draw total contours found\n",
    "text = 'I found {} objects!'.format(len(contours))\n",
    "cv2.putText(output, text, (10, 25), cv2.FONT_HERSHEY_COMPLEX, 0.7 ,(240, 0, 159), 2)\n",
    "cv2.imshow('Count Objects', output)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply Erosion to reduce foreground Image Size\n",
    "mask = thresh.copy()\n",
    "mask = cv2.erode(mask, None, iterations=5)\n",
    "cv2.imshow('Erosion', mask)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply dilation to increase foreground size\n",
    "mask = thresh.copy()\n",
    "mask = cv2.dilate(mask, None, iterations=5)\n",
    "cv2.imshow('Dilation', mask)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a typical operation we may want to apply is to take our mask and\n",
    "# apply a bitwise AND to our input image, keeping only the masked\n",
    "# regions\n",
    "# Background Subtraction\n",
    "mask = thresh.copy()\n",
    "output = cv2.bitwise_and(image, image, mask=mask)\n",
    "cv2.imshow('Bitwise And', output)\n",
    "cv2.waitKey(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
